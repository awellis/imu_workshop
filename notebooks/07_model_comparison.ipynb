{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Model Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have been considering single models, with a focus on parameter estimation. However, we often want to compare different models:\n",
    "\n",
    "These models could be nested, i.e. we want to compare a 'null' model with parameter restrictions to model without these restrictions. Using conventional model comparison techniques, we are restricted to comparing nested models - Bayesian analysis allows to compare arbitrary models.\n",
    "\n",
    "For the moment, we will restrict ourselves to considering nested models, though."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have another look at Bayes rule, only this time we make the dependency of the parameters $\\mathbf{\\theta}$ explicit:\n",
    "\n",
    "$$ p(\\theta | D, \\mathcal{M}) = \\frac{p(D|\\theta, \\mathcal{M}) p(\\theta | \\mathcal{M})}{p(D | \\mathcal{M})}$$\n",
    "\n",
    "where $\\mathcal{M}$ refers to a specific model. The marginal likelihood $p(D | \\mathcal{M})$ now gives the probability of the data, averaged over all possible parameter value under model $\\mathcal{M}$.\n",
    "\n",
    "Writing out marginal likelihood $p(D | \\mathcal{M})$: \n",
    "$$ p(D | \\mathcal{M}) = \\int{p(D | \\theta, \\mathcal{M}) p(\\theta|\\mathcal{M})d\\theta}$$\n",
    "we see that this is averaged over all possible values of $\\theta$ that the model will allow.\n",
    "\n",
    "The important thing to consider here is that the model evidence will depend on what kind of predictions a model can make. This gives us a measure of complexity – **a complex model is a model that can make many predictions**.\n",
    "\n",
    "The problem with making many predictions is that most of these predictions will turn out to be false.\n",
    "\n",
    "The complexity of a model will depend on (among other things):\n",
    "\n",
    "- the number of parameters (as in frequentist model comparison)\n",
    "- the prior distributions of the model's parameters\n",
    "\n",
    "When a parameters priors are broad (uninformative), those parts of the parameter space where the likelihood is high are assigned low probability. Intuitively, by hedging one's bets, one assigns low probability to parameter values that make good predictions.\n",
    "\n",
    "All this leads to the fact that more complex model have comparatively lower marginal likelihood.\n",
    "\n",
    "Therefore, when we compare models, and we prefer models with higher marginal likelihood, we are using Ockham's razor in a principled manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Consider Bart and Lisa, who each get 100 CHF to bet on the winner of the world cup soccer tournament. Bart decides to divide his money evenly over 10 candidate teams, including those from Brazil and Germany. Lisa divides her money over just two teams, betting 60 euros on the team from Brazil and 40 euros on the team from Germany. \n",
    "\n",
    ">Now if either Brazil or Germany turn out to win the 2010 world cup, Lisa wins more money than Bart. Explain in what way this scenario is analogous to the computation of marginal likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also write Bayes rule applied to a comparison between models (marginalized over all parameters within the model):\n",
    "\n",
    "$$ p(\\mathcal{M_1} | D) = \\frac{P(D | \\mathcal{M_1}) p(\\mathcal{M_1})}{p(D)}$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ p(\\mathcal{M_2} | D) = \\frac{P(D | \\mathcal{M_2}) p(\\mathcal{M_2})}{p(D)}$$\n",
    "\n",
    "This tells us that for model $\\mathcal{M_m}$, the posterior probability of the model is proportional to the marginal likelihood times the prior probability of the model.\n",
    "\n",
    "Now, one is usually less interested in absolute evidence than in relative evidence; we want to compare the predictive performance of one model over another.\n",
    "\n",
    "To do this, we simply form the ratio of the model probabilities:\n",
    "\n",
    "$$ \\frac{p(\\mathcal{M_1} | D) = \\frac{P(D | \\mathcal{M_1}) p(\\mathcal{M_1})}{p(D)}} {p(\\mathcal{M_2} | D) = \\frac{P(D | \\mathcal{M_2}) p(\\mathcal{M_2})}{p(D)}}$$\n",
    "\n",
    "The term $p(D)$ cancels out, giving us:\n",
    "$$ \\frac{p(\\mathcal{M_1} | D) = P(D | \\mathcal{M_1}) p(\\mathcal{M_1})} {p(\\mathcal{M_2} | D) = P(D | \\mathcal{M_2}) p(\\mathcal{M_2})}$$\n",
    "\n",
    "The ratio $\\frac{p(\\mathcal{M_1}}{p(\\mathcal{M_2}}$ is called the **prior odds**, and the ratio $\\frac{p(\\mathcal{M_1} | D)}{p(\\mathcal{M_2} | D)}$ is therfore the **posterior odds**.\n",
    "\n",
    "We are particulary interested in the ratio of the marginal likelihoods:\n",
    "\n",
    "$$\\frac{P(D | \\mathcal{M_1})}{P(D | \\mathcal{M_2})}$$\n",
    "\n",
    "This is the <span style=\"color:firebrick\">Bayes factor</span>, and it can be interpreted as the change from prior odds to posterior odds that is indicated by the data.\n",
    "\n",
    "If we consider the prior odds to be $1$, i.e. we do not favour one model over another a priori, then we are only interested in the Bayes factor. We write this as:\n",
    "\n",
    "$$ BF_{12} = \\frac{P(D | \\mathcal{M_1}}{P(D | \\mathcal{M_2}}$$\n",
    "\n",
    "Here, $BF_{12}$ indicates the extent to which the data support model $\\mathcal{M_1}$ over model $\\mathcal{M_2}$.\n",
    "\n",
    "As an example, if we obtain a $BF_{12} = 5$, this mean that the data are 5 times more likely to have occured under model 1 than under model 2. Conversely, if $BF_{12} = 0.2$, then the data are 5 times more likely to have occured under model 2.\n",
    "\n",
    "The following [classification](http://en.wikipedia.org/wiki/Bayes_factor#Interpretation) is sometimes used, although it is unnessecary.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: binomial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's revisit the binomial example. We are interested in whether there is evidence that our participant (9 out of 10 correct answers) is truly performing above chance.\n",
    "\n",
    "We therefore construct 2 models: model 1 says that our participant was guessing, model 2 says that performance was above or below chance (undirected).\n",
    "\n",
    "Model 1: $\\theta = 0.5$\n",
    "\n",
    "This would correspond to the null hypothesis.\n",
    "\n",
    "Model 2: $\\theta \\neq 0.5$\n",
    "\n",
    "Now, the most obvious difference to NHST is that in Bayesian analysis, we need to specify what we mean by \"not guessing\"; it is not enough to simply specify the null hypothesis.\n",
    "\n",
    "As in the previous examples, we can express our prior belief as a Beta distribution – we might start with the prior that all values of $\\theta$ are equally likely:\n",
    "\n",
    "$$ p(\\theta | \\mathcal{M_2}) \\sim Beta(1, 1)$$\n",
    "\n",
    "The marginal likelihood for model 1 can be calculated by plugging in $\\theta = 0.5$ in the binomial equation:\n",
    "\n",
    "$$p(D|\\mathcal{M_1} = \\binom{10}{9}(0.5)^{10} $$\n",
    "\n",
    "The marginal likelihood for model 2 is tricky to calculate, as we need to integrate over all values of $\\theta$, but we can use the fact that if $\\theta$ is uniform, then\n",
    "$$p(D|\\mathcal{M_2}) = \\frac{1}{n +1}$$ \n",
    "\n",
    "Then,\n",
    "$$BF_{12} = \\binom{10}{9}(0.5)^{10} (n + 1) \\approx 0.107$$\n",
    "\n",
    "Of course, a value of < 1 indicates that the data are more likely under model 2, so we can write that the data are $1/0.107 \\approx 9.3$ times more likely under model 2.\n",
    "\n",
    "Normally, however, we cannot work out the Bayes factor analytically – in fact, this is a major problem. There is a nice and simple trick, which works for nested models (Savage-Dickey density ratio test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advantages of using Bayes factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many advantages to using a principled apporach to data analysis, but one of the biggest is that it is possible to obtain *evidence for  the null hypothesis*.\n",
    "\n",
    "In the above example, we could just as well have found evidence in favour of our \"guessing\" model.\n",
    "\n",
    "There are numerous cases in psychology where we want to quantify evidence for the absence of an effect. Uaing Bayes factor allows us to state that we found evidence for \"no effect\", rather than the uninteresting claim that we failed to find evidence against the null.\n",
    "\n",
    "See papers by Jeff Rouder & Richard Morey or chapter 11 of the Kruschke book for a thorough discussion of the advantages of using BF over NHST.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
